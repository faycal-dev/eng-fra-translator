{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T23:20:01.373961Z",
     "iopub.status.busy": "2021-09-22T23:20:01.373582Z",
     "iopub.status.idle": "2021-09-22T23:20:01.386228Z",
     "shell.execute_reply": "2021-09-22T23:20:01.385394Z",
     "shell.execute_reply.started": "2021-09-22T23:20:01.373880Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T23:20:01.643579Z",
     "iopub.status.busy": "2021-09-22T23:20:01.643263Z",
     "iopub.status.idle": "2021-09-22T23:20:02.517210Z",
     "shell.execute_reply": "2021-09-22T23:20:02.516317Z",
     "shell.execute_reply.started": "2021-09-22T23:20:01.643552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.\\tVa !\\tCC-BY 2.0 (France) Attribution: tat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi.\\tSalut !\\tCC-BY 2.0 (France) Attribution: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi.\\tSalut.\\tCC-BY 2.0 (France) Attribution: t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run!\\tCours !\\tCC-BY 2.0 (France) Attribution:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Run!\\tCourez !\\tCC-BY 2.0 (France) Attribution...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  Go.\\tVa !\\tCC-BY 2.0 (France) Attribution: tat...\n",
       "1  Hi.\\tSalut !\\tCC-BY 2.0 (France) Attribution: ...\n",
       "2  Hi.\\tSalut.\\tCC-BY 2.0 (France) Attribution: t...\n",
       "3  Run!\\tCours !\\tCC-BY 2.0 (France) Attribution:...\n",
       "4  Run!\\tCourez !\\tCC-BY 2.0 (France) Attribution..."
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./archive/fra.txt\" , sep='\\n', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T23:20:02.519144Z",
     "iopub.status.busy": "2021-09-22T23:20:02.518817Z",
     "iopub.status.idle": "2021-09-22T23:20:02.526465Z",
     "shell.execute_reply": "2021-09-22T23:20:02.525578Z",
     "shell.execute_reply.started": "2021-09-22T23:20:02.519110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177210, 1)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T23:20:02.553303Z",
     "iopub.status.busy": "2021-09-22T23:20:02.553055Z",
     "iopub.status.idle": "2021-09-22T23:20:02.814204Z",
     "shell.execute_reply": "2021-09-22T23:20:02.813397Z",
     "shell.execute_reply.started": "2021-09-22T23:20:02.553278Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"english\"] = df[0].apply(lambda x: x.split('\\t')[0])\n",
    "df[\"french\"] = df[0].apply(lambda x: x.split('\\t')[1])  \n",
    "df.drop(0,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T23:20:02.959859Z",
     "iopub.status.busy": "2021-09-22T23:20:02.959573Z",
     "iopub.status.idle": "2021-09-22T23:20:02.969905Z",
     "shell.execute_reply": "2021-09-22T23:20:02.968923Z",
     "shell.execute_reply.started": "2021-09-22T23:20:02.959832Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>french</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Cours !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Courez !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  english    french\n",
       "0     Go.      Va !\n",
       "1     Hi.   Salut !\n",
       "2     Hi.    Salut.\n",
       "3    Run!   Cours !\n",
       "4    Run!  Courez !"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T23:20:03.435595Z",
     "iopub.status.busy": "2021-09-22T23:20:03.435270Z",
     "iopub.status.idle": "2021-09-22T23:20:04.295431Z",
     "shell.execute_reply": "2021-09-22T23:20:04.294444Z",
     "shell.execute_reply.started": "2021-09-22T23:20:03.435566Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>french</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi</td>\n",
       "      <td>salut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hi</td>\n",
       "      <td>salut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>run</td>\n",
       "      <td>cours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>run</td>\n",
       "      <td>courez</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  english   french\n",
       "0      go      va \n",
       "1      hi   salut \n",
       "2      hi    salut\n",
       "3     run   cours \n",
       "4     run  courez "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "# here we remouve ponctuation and lower the text\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "df[\"english\"] = df[\"english\"].apply(lambda x: x.lower().translate(translator))\n",
    "df[\"french\"] = df[\"french\"].apply(lambda x: x.lower().translate(translator))  \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T23:20:05.136055Z",
     "iopub.status.busy": "2021-09-22T23:20:05.135750Z",
     "iopub.status.idle": "2021-09-22T23:20:09.206332Z",
     "shell.execute_reply": "2021-09-22T23:20:09.205543Z",
     "shell.execute_reply.started": "2021-09-22T23:20:05.136026Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "french_tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T23:20:09.208073Z",
     "iopub.status.busy": "2021-09-22T23:20:09.207734Z",
     "iopub.status.idle": "2021-09-22T23:20:11.757657Z",
     "shell.execute_reply": "2021-09-22T23:20:11.756800Z",
     "shell.execute_reply.started": "2021-09-22T23:20:09.208037Z"
    }
   },
   "outputs": [],
   "source": [
    "french_tokenizer.fit_on_texts(df[\"french\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T23:20:11.759576Z",
     "iopub.status.busy": "2021-09-22T23:20:11.759299Z",
     "iopub.status.idle": "2021-09-22T23:20:11.767396Z",
     "shell.execute_reply": "2021-09-22T23:20:11.766492Z",
     "shell.execute_reply.started": "2021-09-22T23:20:11.759547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the french vocab size is 33484\n"
     ]
    }
   ],
   "source": [
    "frensh_vocab_size = len(french_tokenizer.word_index) + 1\n",
    "print(f\"the french vocab size is {frensh_vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T23:20:11.769239Z",
     "iopub.status.busy": "2021-09-22T23:20:11.768893Z",
     "iopub.status.idle": "2021-09-22T23:20:13.718462Z",
     "shell.execute_reply": "2021-09-22T23:20:13.717599Z",
     "shell.execute_reply.started": "2021-09-22T23:20:11.769205Z"
    }
   },
   "outputs": [],
   "source": [
    "english_tokenizer = Tokenizer()\n",
    "english_tokenizer.fit_on_texts(df[\"english\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T23:20:13.720248Z",
     "iopub.status.busy": "2021-09-22T23:20:13.719747Z",
     "iopub.status.idle": "2021-09-22T23:20:13.725008Z",
     "shell.execute_reply": "2021-09-22T23:20:13.724161Z",
     "shell.execute_reply.started": "2021-09-22T23:20:13.720208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the english vocab size is 14783\n"
     ]
    }
   ],
   "source": [
    "english_vocab_size = len(english_tokenizer.word_index) + 1\n",
    "print(f\"the english vocab size is {english_vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T23:20:13.726663Z",
     "iopub.status.busy": "2021-09-22T23:20:13.726171Z",
     "iopub.status.idle": "2021-09-22T23:20:13.736387Z",
     "shell.execute_reply": "2021-09-22T23:20:13.735568Z",
     "shell.execute_reply.started": "2021-09-22T23:20:13.726614Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T23:20:13.739757Z",
     "iopub.status.busy": "2021-09-22T23:20:13.739187Z",
     "iopub.status.idle": "2021-09-22T23:20:20.008042Z",
     "shell.execute_reply": "2021-09-22T23:20:20.007000Z",
     "shell.execute_reply.started": "2021-09-22T23:20:13.739720Z"
    }
   },
   "outputs": [],
   "source": [
    "x = english_tokenizer.texts_to_sequences(df[\"english\"])\n",
    "y = french_tokenizer.texts_to_sequences(df[\"french\"])\n",
    "x = pad_sequences(x, padding='post')\n",
    "y = pad_sequences(y, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T23:20:20.010802Z",
     "iopub.status.busy": "2021-09-22T23:20:20.010441Z",
     "iopub.status.idle": "2021-09-22T23:20:20.042953Z",
     "shell.execute_reply": "2021-09-22T23:20:20.042018Z",
     "shell.execute_reply.started": "2021-09-22T23:20:20.010757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((177210, 44), (177210, 55))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T23:20:20.044715Z",
     "iopub.status.busy": "2021-09-22T23:20:20.044347Z",
     "iopub.status.idle": "2021-09-22T23:20:20.049064Z",
     "shell.execute_reply": "2021-09-22T23:20:20.048176Z",
     "shell.execute_reply.started": "2021-09-22T23:20:20.044678Z"
    }
   },
   "outputs": [],
   "source": [
    "# now lets create our decoder encoder architecture\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Bidirectional, LSTM, RepeatVector, Dense, TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T23:20:20.050971Z",
     "iopub.status.busy": "2021-09-22T23:20:20.050616Z",
     "iopub.status.idle": "2021-09-22T23:20:23.153984Z",
     "shell.execute_reply": "2021-09-22T23:20:23.153164Z",
     "shell.execute_reply.started": "2021-09-22T23:20:20.050934Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# the encoder:\n",
    "model.add(Embedding(english_vocab_size, 128, input_length=x.shape[1]))\n",
    "model.add(Bidirectional(LSTM(256)))\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "model.add(RepeatVector(y.shape[1]))\n",
    "# the decoder:\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(Dense(frensh_vocab_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T23:20:23.155657Z",
     "iopub.status.busy": "2021-09-22T23:20:23.155304Z",
     "iopub.status.idle": "2021-09-22T23:20:23.171532Z",
     "shell.execute_reply": "2021-09-22T23:20:23.170603Z",
     "shell.execute_reply.started": "2021-09-22T23:20:23.155620Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-22T23:20:23.173046Z",
     "iopub.status.busy": "2021-09-22T23:20:23.172711Z",
     "iopub.status.idle": "2021-09-23T00:42:12.325348Z",
     "shell.execute_reply": "2021-09-23T00:42:12.322983Z",
     "shell.execute_reply.started": "2021-09-22T23:20:23.173011Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(x,y, epochs=30, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-23T00:42:20.698576Z",
     "iopub.status.busy": "2021-09-23T00:42:20.698226Z",
     "iopub.status.idle": "2021-09-23T00:42:21.370650Z",
     "shell.execute_reply": "2021-09-23T00:42:21.369683Z",
     "shell.execute_reply.started": "2021-09-23T00:42:20.698543Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")\n",
    "model.save_weights(\"model.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"./model.h5\")\n",
    "model.load_weights('./model.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-23T00:42:51.294161Z",
     "iopub.status.busy": "2021-09-23T00:42:51.293849Z",
     "iopub.status.idle": "2021-09-23T00:42:51.301204Z",
     "shell.execute_reply": "2021-09-23T00:42:51.300381Z",
     "shell.execute_reply.started": "2021-09-23T00:42:51.294132Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 42,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0],\n",
       "       [  1, 114, 540,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0],\n",
       "       [ 55,  32,  23, 874,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0],\n",
       "       [  1, 130, 339,  11,  45,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [\"go\",\"i am hungry\",'get on your horse','i made fun of him']\n",
    "test = english_tokenizer.texts_to_sequences(test)\n",
    "test = pad_sequences(test,maxlen=44, padding='post')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-23T00:43:00.544857Z",
     "iopub.status.busy": "2021-09-23T00:43:00.544539Z",
     "iopub.status.idle": "2021-09-23T00:43:01.688118Z",
     "shell.execute_reply": "2021-09-23T00:43:01.687341Z",
     "shell.execute_reply.started": "2021-09-23T00:43:00.544826Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 55, 33484)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(test)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-23T00:43:11.238092Z",
     "iopub.status.busy": "2021-09-23T00:43:11.237768Z",
     "iopub.status.idle": "2021-09-23T00:43:11.253460Z",
     "shell.execute_reply": "2021-09-23T00:43:11.252667Z",
     "shell.execute_reply.started": "2021-09-23T00:43:11.238061Z"
    }
   },
   "outputs": [],
   "source": [
    "# take the chosen word for every sentence\n",
    "y_pred = [[np.argmax(w) for w in sentence] for sentence in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-23T00:43:23.436844Z",
     "iopub.status.busy": "2021-09-23T00:43:23.436520Z",
     "iopub.status.idle": "2021-09-23T00:43:23.443378Z",
     "shell.execute_reply": "2021-09-23T00:43:23.442400Z",
     "shell.execute_reply.started": "2021-09-23T00:43:23.436813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 55)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.array(y_pred)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-23T00:43:38.086403Z",
     "iopub.status.busy": "2021-09-23T00:43:38.086051Z",
     "iopub.status.idle": "2021-09-23T00:43:38.093218Z",
     "shell.execute_reply": "2021-09-23T00:43:38.092273Z",
     "shell.execute_reply.started": "2021-09-23T00:43:38.086352Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['allez', 'jai faim', 'sors à cheval\\xa0', 'je me suis un']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn it into text\n",
    "y_pred = french_tokenizer.sequences_to_texts(y_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-23T00:56:35.857234Z",
     "iopub.status.busy": "2021-09-23T00:56:35.856788Z",
     "iopub.status.idle": "2021-09-23T00:56:35.867662Z",
     "shell.execute_reply": "2021-09-23T00:56:35.866553Z",
     "shell.execute_reply.started": "2021-09-23T00:56:35.857160Z"
    }
   },
   "outputs": [],
   "source": [
    "def translate(model, eng_tokenizer,fra_tokenizer, sentence):\n",
    "    text = [sentence]\n",
    "    text = eng_tokenizer.texts_to_sequences(text)\n",
    "    text = pad_sequences(text,maxlen=44, padding='post')\n",
    "    pred = model.predict(text)\n",
    "    pred = [[np.argmax(w) for w in sentence] for sentence in pred]\n",
    "    pred = fra_tokenizer.sequences_to_texts(pred)\n",
    "    return pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-23T01:02:08.049433Z",
     "iopub.status.busy": "2021-09-23T01:02:08.049096Z",
     "iopub.status.idle": "2021-09-23T01:02:08.292205Z",
     "shell.execute_reply": "2021-09-23T01:02:08.291340Z",
     "shell.execute_reply.started": "2021-09-23T01:02:08.049402Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love you -----> je taime\n",
      "the work is hard -----> le travail est difficile\n",
      "i need money -----> jai besoin de largent\n",
      "call me later -----> appellemoi pour tard\n",
      "the french president is going to visit japan next month -----> le président de est en à en mois mois\n",
      "thats the worst thing that could possibly happen -----> cest la chose qui qui qui puisse\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\"i love you\",\"the work is hard\",\"i need money\", \"call me later\",'the french president is going to visit japan next month','thats the worst thing that could possibly happen']\n",
    "for i in range(len(test_sentences)):\n",
    "    print(f\"{test_sentences[i]} -----> {translate(model,english_tokenizer,french_tokenizer, test_sentences[i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with more training and a bigger dataset we can achieve a much better accuracy since with only 20 epochs it is working pretty well with small sentences "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
